# -*- coding: utf-8 -*-
"""spark_new_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19lN-16HgxJcW099JoFMXEpPTH7WfyJNL

# **Installing Dependencies**
"""

!pip install -q datasets transformers evaluate

!pip install git+https://github.com/tensorflow/examples.git

!pip install pyspark

!pip install tensorflow_addons

"""# **Importing Libraries**"""

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow_examples.models.pix2pix import pix2pix
from IPython.display import clear_output
import matplotlib.pyplot as plt
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.sql.functions import col
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

"""# **Starting Spark Session**"""

from pyspark.sql import SparkSession
import tensorflow as tf
import tensorflow_datasets as tfds

# Initialize SparkSession
spark = SparkSession.builder \
    .appName("TensorFlowOnSpark") \
    .getOrCreate()

"""# **Getting Dataset**"""

dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)

"""# **Loading Dataset**"""

def load_image(datapoint):
  input_image = tf.image.resize(datapoint['image'], (128, 128))
  input_mask = tf.image.resize(
    datapoint['segmentation_mask'],
    (128, 128),
    method = tf.image.ResizeMethod.NEAREST_NEIGHBOR,
  )

  input_image, input_mask = normalize(input_image, input_mask)

  return input_image, input_mask

"""# **Normalizing Dataset**"""

def normalize(input_image, input_mask):
  input_image = tf.cast(input_image, tf.float32) / 255.0
  input_mask -= 1
  return input_image, input_mask

"""# **Making Train and Test sets**"""

TRAIN_LENGTH = info.splits['train'].num_examples
BATCH_SIZE = 64
BUFFER_SIZE = 1000
STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE

train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)
test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)

"""# **Augumenting Images**"""

class Augment(tf.keras.layers.Layer):
  def __init__(self, seed=42):
    super().__init__()
    # both use the same seed, so they'll make the same random changes.
    self.augment_inputs = tf.keras.layers.RandomFlip(mode="horizontal", seed=seed)
    self.augment_labels = tf.keras.layers.RandomFlip(mode="horizontal", seed=seed)

  def call(self, inputs, labels):
    inputs = self.augment_inputs(inputs)
    labels = self.augment_labels(labels)
    return inputs, labels

train_batches = (
    train_images
    .cache()
    .shuffle(BUFFER_SIZE)
    .batch(BATCH_SIZE)
    .repeat()
    .map(Augment())
    .prefetch(buffer_size=tf.data.AUTOTUNE))

test_batches = test_images.batch(BATCH_SIZE)

"""# **Display Function**"""

def display(display_list):
  plt.figure(figsize=(15, 15))

  title = ['Input Image', 'True Mask', 'Predicted Mask']

  for i in range(len(display_list)):
    plt.subplot(1, len(display_list), i+1)
    plt.title(title[i])
    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))
    plt.axis('off')
  plt.show()

"""# **Model before finetuning**"""

for images, masks in train_batches.take(2):
  sample_image, sample_mask = images[0], masks[0]
  display([sample_image, sample_mask])

"""# **Defining Model Architecture**"""

base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)

# Use the activations of these layers
layer_names = [
    'block_1_expand_relu',   # 64x64
    'block_3_expand_relu',   # 32x32
    'block_6_expand_relu',   # 16x16
    'block_13_expand_relu',  # 8x8
    'block_16_project',      # 4x4
]
base_model_outputs = [base_model.get_layer(name).output for name in layer_names]

# Create the feature extraction model
down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)

down_stack.trainable = False

import tensorflow as tf
from tensorflow.keras.layers import LayerNormalization, Concatenate, Conv2DTranspose

# Custom upsampling layer using Transformer and Conv2DTranspose
class TransformerUpsample(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):
        super(TransformerUpsample, self).__init__()

        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)
        self.conv1 = tf.keras.layers.Conv2DTranspose(d_model, 3, strides=2, padding='same')
        self.conv2 = tf.keras.layers.Conv2D(target_vocab_size, 3, padding='same')
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)

    def call(self, inputs, training=True):
        attn_output = self.mha(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        out2 = self.conv1(out1)
        out2 = self.dropout2(out2, training=training)
        out3 = self.conv2(out2)
        return out3

# Modify up_stack to use TransformerUpsample
up_stack = [
    TransformerUpsample(d_model=512, num_heads=8, dff=2048, target_vocab_size=64, maximum_position_encoding=64),  # 4x4 -> 8x8
    TransformerUpsample(d_model=256, num_heads=8, dff=1024, target_vocab_size=64, maximum_position_encoding=64),  # 8x8 -> 16x16
    TransformerUpsample(d_model=128, num_heads=8, dff=512, target_vocab_size=64, maximum_position_encoding=64),  # 16x16 -> 32x32
    TransformerUpsample(d_model=64, num_heads=8, dff=256, target_vocab_size=64, maximum_position_encoding=64),  # 32x32 -> 64x64
]

def unet_model(output_channels: int):
    inputs = tf.keras.layers.Input(shape=[128, 128, 3])

    # Downsampling through the model
    skips = down_stack(inputs)
    x = skips[-1]
    skips = reversed(skips[:-1])

    # Upsampling and establishing the skip connections
    for up, skip in zip(up_stack, skips):
        x = up(x, training=True)  # Note the addition of the 'training=True' argument
        concat = Concatenate()
        x = concat([x, skip])

    # This is the last layer of the model
    last = Conv2DTranspose(
        filters=output_channels, kernel_size=3, strides=2, padding='same')  #64x64 -> 128x128

    x = last(x)

    return tf.keras.Model(inputs=inputs, outputs=x)

# Create U-Net model
output_channels = 3  # Assuming RGB images
model = unet_model(output_channels)

OUTPUT_CLASSES = 3

model = unet_model(output_channels=OUTPUT_CLASSES)
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""# **Visualising Model**"""

tf.keras.utils.plot_model(model, show_shapes=True)

"""# **Creating Mask Function and Showing Predictions**"""

def create_mask(pred_mask):
  pred_mask = tf.math.argmax(pred_mask, axis=-1)
  pred_mask = pred_mask[..., tf.newaxis]
  return pred_mask[0]

def show_predictions(dataset=None, num=1):
  if dataset:
    for image, mask in dataset.take(num):
      pred_mask = model.predict(image)
      display([image[0], mask[0], create_mask(pred_mask)])
  else:
    display([sample_image, sample_mask,
             create_mask(model.predict(sample_image[tf.newaxis, ...]))])

show_predictions()

class DisplayCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs=None):
    clear_output(wait=True)
    show_predictions()
    print ('\nSample Prediction after epoch {}\n'.format(epoch+1))

show_predictions(test_batches, 3)

"""# **Training Model**"""

EPOCHS = 20
VAL_SUBSPLITS = 5
VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS

model_history = model.fit(train_batches, epochs=EPOCHS,
                          steps_per_epoch=STEPS_PER_EPOCH,
                          validation_steps=VALIDATION_STEPS,
                          validation_data=test_batches,
                          callbacks=[DisplayCallback()])

"""Visualising Loss"""

loss = model_history.history['loss']
val_loss = model_history.history['val_loss']

plt.figure()
plt.plot(model_history.epoch, loss, 'r', label='Training loss',color="red")
plt.plot(model_history.epoch, val_loss, 'r', label='Validation loss',color="green")
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss Value')
plt.ylim([0, 1])
plt.legend()
plt.show()

"""# **Calculating IoU Score**"""

import numpy as np

def calculate_iou(y_true, y_pred):
    # Flatten the masks
    y_true_flatten = tf.reshape(y_true, [-1])
    y_pred_flatten = tf.reshape(y_pred, [-1])

    # Calculate intersection and union
    intersection = tf.reduce_sum(y_true_flatten * y_pred_flatten)
    union = tf.reduce_sum(y_true_flatten) + tf.reduce_sum(y_pred_flatten) - intersection

    # Calculate IoU
    iou = intersection / (union)  # Adding a small epsilon to avoid division by zero

    return iou

iou_scores = []

for images, masks in test_batches:
    pred_masks = model.predict(images)
    for true_mask, pred_mask in zip(masks, pred_masks):
        true_mask = create_mask(true_mask)
        pred_mask = create_mask(pred_mask)
        iou = calculate_iou(true_mask, pred_mask)
        iou_scores.append(iou.numpy())

mean_iou = np.mean(iou_scores)
print("Mean IoU score for test samples:", mean_iou)

"""# **Stopping Spark**"""

spark.stop()